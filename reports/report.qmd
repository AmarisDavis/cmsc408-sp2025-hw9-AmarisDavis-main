---
title: Homework 9 - World Bank - Population Analysis
---


GITHUB URL:  <https://github.com/cmsc-vcu/cmsc408-sp2025-hw9-template>

This assignment focuses on the SELECT statement with joins and other fun features.  As context, we'll be conducting an analysis of some real-world data use SQL to reveal answers.

This QMD provides a tidy scaffold within which you add all of your code.

**Instructions**: Please complete the python SQL sections as noted.  I'll be providing you with a bare minimum scaffold of working code so feel free to improvise as necessary.

**DO NOT add or remove python sections.**  The autograder depends on the sections in the approprite order.

# Problem Background

This population analysis assignment stems fromt he previous assignment with the country classifications. We are now analyzing 60+ years of data for over 200+ countries. We'll be using the data to answer questions like "How many people live in the North America region". We're using SQL to pull data around to synthesize and reduce and extract information from the raw data.

```{python}
from helpers import create_database_engine, run_sql_and_return_df, run_sql_and_return_html, create_db_wrapper, execute_ddl_from_file, execute_ddl

# Load these variables from .env file.
config_map = {
  'user': "CMSC408_HW9_USER",
  'password': "CMSC408_HW9_PASSWORD",
  'host': "CMSC408_HW9_HOST",
  'database': "CMSC408_HW9_DB_NAME"
}

cnx,config = create_db_wrapper( config_map )
  
```

You should see 3 tables in the list below.


```{python}
# Do a quick test of the connection by listing all the WDI table in the world_bank_data schema.

run_sql_and_return_df(cnx,f"""
select
  table_schema, table_name, table_rows
from
  information_schema.tables
where
  1=1
  and table_name like 'wdi%%'
  and table_schema = 'world_bank_data';
""")

```

# Exercises

## Task 1

Clean up your _users_ schema.  Drop all the tables.  NOTE - if you have foreign keys
set up in the schema, the order that you drop files will matter!

```{python}
# Drop wdi_country
sql = """
drop table if exists wdi_country;
drop table if exists wdi_series;
drop table if exists wdi_data;
drop table if exists wdi_data_stacked;
-- drop all other files in your schema.  It should be empty!
commit;
"""
execute_ddl( cnx, sql );
```

Verify that it all worked.  This query should return "no records returned".

```{python}
run_sql_and_return_df(cnx,f"""
select
  table_schema, table_name, table_rows
from
  information_schema.tables
where
  1=1
  and table_name like 'wdi%%'
  and table_schema = DATABASE();
""")
```


## Task 2

Create a local copy of wdi_data with just countries.  

```{python}
execute_ddl( cnx, """
create table wdi_country as
select * 
from world_bank_data.wdi_country
where
not region is NULL
""")
```

Verify that you've got the correct number of countries.

```{python}
run_sql_and_return_df(cnx,f"""
select 'wdi_country',count(*) from wdi_country;
""")
```

## Task 3


```{python}
## OK, but what the heck are these datum?  The WDI_SERIES data offer
## "meta-data" that describes the "data" in the WDI_DATA file.  WRITE
## a query that provides descriptions for the indicators in the WDI_DATA
## table using information from the WDI_SERIES table.
##
## Your result should include 3 columns (series code, indicator name and
## long definition)
##
## You need to determine which columns join the two tables.
##
## ALSO, use this filter:  where `Series Code` like 'SP.POP.TOTL%%'
##
## Use tables from the `world_bank_data` schema.  DO NOT make local copies!
## 
## (skills: select, subquery)

run_sql_and_return_df(cnx,"""
select 
    s.`Series Code` as series_code,
    s.`Indicator Name` as indicator_name,
    s.`Long definition` as long_definition
from 
    world_bank_data.wdi_series s
where 
    s.`Series Code` like 'SP.POP.TOTL%%'
 
""")
```

## Task 4

```{python}
## INTERESTING! Now let's work with the WDI_DATA table.
##
## To start, write a quick query that takes a peek at the first
## 10 records or so of WDI_DATA.
##
## Umh... It seems that each row of the WDI_SERIES file contains
## data for a single measure (or indicator) for the years 1960 to 2023
##
## ARE YOU READY?
##
## What was the world population in 1960 and in 2023?
##
## (your result should have 5 columns, the country name, the indicator name,
## the indicator code, and the populations in 1960 and the population in 2023).
##
## Remember how we eliminated all the "non-country" codes from WDI_COUNTRY
## back in task 2?  The WDI_DATA table still contains them.
##
## BUT - that is OK, because one of the country names is "World".
## Looking at the results of Task 3 - also filter on the most appropriate
## `Indicator Code`.
##
## SO, keeping it simple, there are no joins or subqueries.
## Your result should have 5 columns and 1 row.
## ALSO, use FORMAT to make the resulting values pretty!
#
## (skills: select)
##
run_sql_and_return_df(cnx,"""
select
`Country Name` as country_name,
`Indicator Name` as indicator_code,
`Indicator Code` as indicator_code,
FORMAT(`1960`, 0) as population_1960,
FORMAT(`2023`, 0) as population_2023
from
world_bank_data.wdi_data
where 
`Country Name` = 'World'
AND `Indicator Code` = 'SP.POP.TOTL'
LIMIT 1;
""")
```

## Task 5

```{python}
## That was fun! Let's investigate the other SP.POP.TOTL values.
## Use a filter `Indicator Code` like 'SP.POP.TOTL%%'
##
## (your result should have 5 columns, the country name, the indicator name,
## the indicator code, and the populations in 1960 and the population in 2023).
##
## (keeping it simple, there are no joins necessary.)
## (skills: select)
##

run_sql_and_return_df(cnx,"""
SELECT 
    `Country Name` AS "Country Name",
    `Indicator Name` AS "Indicator Name", 
    `Indicator Code` AS "Indicator Code",
    FORMAT(`1960`, 0) AS "1960",
    FORMAT(`2023`, 0) AS "2023"
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'
    AND `Country Name` = 'World'
ORDER BY 
    CASE 
        WHEN `Indicator Code` = 'SP.POP.TOTL' THEN 2  -- Total population last
        ELSE 1  -- All other rows first
    END,
    `Indicator Code`;
""")
```


## Task 6

```{python}
## What is the percentage of females in the world in 1960 and in 2023,
## compared with the percentage of females in the US?
##
## The pre-calculated values are rounded to the nearest percent.  We need
## at least 3 digits past the decimal point.  SO, we're going to have
## to calculate it ourselves.
##
## (your result should consist of two rows ('World' and 'United States') and four columns:
## the country name, the description ("Percent female"), the 1960
## percent female and the 2023 percent female.
##
## Numeric values should show 3 places past the decimal AND include a 
## % sign,  e.g., 33.333%  or 59.151%)
##
## (skills: select, aggregate, subquery/with, format, concat)

run_sql_and_return_df(cnx,"""
SELECT 
    `Country Name` AS "Country Name",
    'Percent Female' AS "Description",
    CONCAT(ROUND(`1960`, 3), '%%') AS "1960",
    CONCAT(ROUND(`2023`, 3), '%%') AS "2023"
FROM 
    world_bank_data.wdi_data
WHERE 
    `Country Name` = 'World'
    AND `Indicator Code` = 'SP.POP.TOTL.FE.ZS'
""")

```

## Task 7


```{python}
## WOW! that was difficult! Seems like a lot of work, forced to hardcode
## years and values just to calculate percentages for these data.
##
## IS THERE A SIMPLER WAY?
##
## When doing data analysis, how your data are stacked make a difference.
## Our lives would be much simpler if we rearranged the data with indicators
## in the columns and years in the rows.
##
## BUT HOW??  
##
## The table WDI_DATA is currently stored in what is call a "wide format".
## The data can be transformed into a more manageble format, in this case
## a "stacked format" that will let us pivot things around much simpler.
##
## Create a new table named "wdi_data_stacked" containing stacked data from
## WDI_DATA. Each row should have four columns: country_code, indicator_code,
## year_code, and a value associated with the year.
##
## Filter WDI_DATA on just the population code 'SP.POP.TOTL%%' 
## Keep all country codes.
##
## Stack data for 1960, 1970, 1980, 1990, 2000, 2010, and 2020
## (skills: create table with select, UNION)

execute_ddl(cnx,"""
DROP TABLE IF EXISTS wdi_data_stacked;

CREATE TABLE wdi_data_stacked AS
SELECT 
    `Country Code` AS country_code,
    `Indicator Code` AS indicator_code,
    '1960' AS year_code,
    `1960` AS value
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '1970',
    `1970`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '1980',
    `1980`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '1990',
    `1990`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '2000',
    `2000`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '2010',
    `2010`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%'

UNION ALL

SELECT 
    `Country Code`,
    `Indicator Code`,
    '2020',
    `2020`
FROM 
    world_bank_data.wdi_data
WHERE 
    `Indicator Code` LIKE 'SP.POP.TOTL%%';
""")
```

```{python}
## Verify the number of records
run_sql_and_return_df(cnx,"""
SELECT COUNT(*) FROM wdi_data_stacked
""")
```

## Task 8

```{python}
## Time to get practice working with our newly stacked data!
##
## Create a summary table of the number of records in each year bundle

run_sql_and_return_df(cnx,"""
select
  year_code as year,
  count(*)
from
  wdi_data_stacked
group by
  year_code
order by
  year_code;
""")
```

## Task 9

```{python}
## Phew. Glad that's over!  Let's recalculate percentage females for the
## World and all decade years in our new wdi_data_stacked table.
##
## Your result should have five columns: country code, yeear, pct female,
## pop female, and total pop.
##  
## (skills: select, aggregate, WITH/subquery, FORMAT)
##

run_sql_and_return_df(cnx,"""
SELECT 
    year_code,
    indicator_code,
    value
FROM 
    wdi_data_stacked
WHERE 
    country_code = 'WLD'
    AND year_code IN ('1960','1970','1980','1990','2000','2010','2020')
    AND indicator_code IN ('SP.POP.TOTL', 'SP.POP.TOTL.FE')
ORDER BY
    year_code, indicator_code;
""")

```

## Task 10

```{python}
## Cool. Now let's compare the Pct. Female of US with the World over
## all the decade years.
##
## You'll only need to modify the query from Task 9!
## Your final table should have three columns: Year, US-Pct-Female and World-PCT-Female
## and one row per year (1960, 1970, etc.)
##
## (skills: select, aggregate, WITH/subquery, FORMAT)
##

run_sql_and_return_df(cnx,"""
WITH country_data AS (
    SELECT 
        country_code,
        year_code,
        indicator_code,
        value
    FROM 
        wdi_data_stacked
    WHERE 
        country_code IN ('WLD', 'USA')
        AND indicator_code IN ('SP.POP.TOTL', 'SP.POP.TOTL.FE.ZS')
        AND year_code IN ('1960','1970','1980','1990','2000','2010','2020')
),

pivoted_data AS (
    SELECT
        year_code,
        MAX(CASE WHEN country_code = 'USA' AND indicator_code = 'SP.POP.TOTL.FE.ZS' THEN value END) AS usa_pct,
        MAX(CASE WHEN country_code = 'WLD' AND indicator_code = 'SP.POP.TOTL.FE.ZS' THEN value END) AS world_pct
    FROM
        country_data
    GROUP BY
        year_code
)

SELECT
    year_code AS "Year",
    CONCAT(ROUND(usa_pct, 3), '%%') AS "Pct Female USA",
    CONCAT(ROUND(world_pct, 3), '%%') AS "Pct Female WLD"
FROM
    pivoted_data
WHERE
    usa_pct IS NOT NULL
    AND world_pct IS NOT NULL
ORDER BY
    year_code;
""")
```

## Task 11

```{python}
## OK. Ghost-pepper hot is nothing.  This is WAY HOTTER than that!!!
##
## Prepare a table comparing pct female by region in the world (rows) by
## decade (columns, 1960-2020).
##
## This is very much like Tasks 9 and 10, except you'll need to do a bit more
## pre-processing to map country codes to regions using our cleaned wdi_country table
## from the earlier tasks.
##
## Build your query in layers, one WITH CTE at a time, checking each CTE to make sure
## you've gathered the data that you need.
##
## Steps:
## 1) Join wdi_country to wdi_data_stacked on `Country Code` for each year and indicator and country code and region
## 2) then, following task 9, aggregate the female and total populations to columns by region and year
## 3) then calculate the pct female for each year and region pair,
## 4) pivot out (using CASE) the years
##
## (skills: select, aggregate, WITH/subquery, CASE, FORMAT)
##

run_sql_and_return_df(cnx,"""
WITH region_data AS (
    SELECT 
        c.region,
        s.year_code,
        AVG(s.value) AS avg_pct_female
    FROM 
        wdi_data_stacked s
    JOIN 
        wdi_country c ON s.country_code = c.`Country Code`
    WHERE 
        s.indicator_code = 'SP.POP.TOTL.FE.ZS'
        AND s.year_code IN ('1960','1970','1980','1990','2000','2010','2020')
    GROUP BY 
        c.region, s.year_code
)
SELECT
    region AS "Region",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '1960' THEN avg_pct_female END), 3), '%%') AS "1960",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '1970' THEN avg_pct_female END), 3), '%%') AS "1970",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '1980' THEN avg_pct_female END), 3), '%%') AS "1980",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '1990' THEN avg_pct_female END), 3), '%%') AS "1990",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '2000' THEN avg_pct_female END), 3), '%%') AS "2000",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '2010' THEN avg_pct_female END), 3), '%%') AS "2010",
    CONCAT(ROUND(MAX(CASE WHEN year_code = '2020' THEN avg_pct_female END), 3), '%%') AS "2020"
FROM
    region_data
GROUP BY
    region
ORDER BY
    region;
""")
```

## Done!


# Reflection

1. In Task 3, you worked on joining tables to retrieve metadata describing the data in the WDI_DATA table. Reflect on the process of identifying relationships between tables. Why is understanding metadata important when working with datasets, and how does it enhance your ability to interpret and analyze the data?

Task three helped me understand the wdi_data table a bit more. Identifying the relationships made it easier for me to make sure i linked the countries, indicators, and years correctly. Understanding metadata is important because it provides context to raw data. Without it, it easier to misinterpret the information being given. 

2. Task 7 required transforming data from a wide format to a stacked format to simplify further analysis. What challenges did you encounter while designing and implementing this transformation? How might changing the format of data impact the efficiency of queries and analyses in real-world scenarios?

It was hard for me to even get the table showing but that was because I was using '%' instead of '%%' because it kept throwing a format error. ANother challenge was making sure i ddin't lose any data in the process. At one point i kept getting none in my table, but again, just a formatting error and learning how to use UNION ALL. Changing the format makes it easier to query the data across different dimensions. In the real world, working with properly formated data can improve the speed and clarity of analysis.

3. Task 11 involved using Common Table Expressions (CTEs) to build a query incrementally, combining multiple layers of data processing. How did using CTEs help you organize and debug your query? Reflect on the advantages and potential challenges of using CTEs in SQL for complex data aggregations and transformations.

Using CTEs helped me make the query step by step. The logic was easier to debug instead of writing out some complicated mess. I could break this task down into easy to manage parts and i counld test each part. The main advantage to this was improved readablility and easy maintainence. One thing that can pose as a challange though is the run time  because it did take a while for this query to load and run properly for me. 

# README

Below is the README from my project.

::: {style="background:lightgray; margin-left:20px; border-top: 3px solid black; border-bottom: 3px solid black; padding-left:20px; padding-right:20px"}
{{< include ../README.md >}}
:::
